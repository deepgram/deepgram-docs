---
title: Deploy Deepgram Aura-2 Self-Hosted Services
subtitle: With Docker/Podman
slug: docs/deploy-aura-2-self-hosted
description: Aura-2 self-hosted deployment guide
hidden: true
---

As with other Deepgram self-hosted services, the Aura-2 services are distributed as container images, as described in the [Deployment Environments](/docs/self-hosted-deployment-environments#container-orchestration) overview. You need to download and deploy these images from a container image repository. You also need to download configuration files and a license file that will be given to you directly by Deepgram.

## Prerequisites

Before you begin, you will need to complete the [Deployment Environments](/docs/self-hosted-deployment-environments) guide, as well as all sub-guides to complete your environment configuration.

You will also need to complete the [Self Service Licensing & Credentials](/docs/self-hosted-self-service-tutorial) guide to authenticate your products with Deepgram's licensing servers and pull Deepgram container images from [Quay](https://quay.io).

## Get Deepgram Products

### Cache Container Image Repository Credentials

Use the image repository credentials you generated in the [self-service licensing and credentials](/docs/on-prem-self-service-tutorial#create-a-set-of-container-image-distribution-credentials) guide to login to Quay on your deployment environment. Once your credentials are cached locally, you should not have to log in again (until after you manually log out).

<CodeGroup>
  ```shell Shell
  # Complete with login information generated in Deepgram Console                                                                                                                                          
  docker login quay.io
  ```
</CodeGroup>

## Import Your Docker Compose, Container Configuration, and Model Files

Before you can run your self-hosted deployment, you must configure the required components. To do this, you will need to customize your configuration files.

1. In your home directory, create the following directories. This is where you will save your Docker Compose file, the Aura-2 API configuration file, and the Aura-2 Engine license file.

   <CodeGroup>
     ```shell Shell
     mkdir config
     ```
   </CodeGroup>

2. Deepgram will provide you with the following required configuration files:
   - `docker-config.yml` - The Docker Compose configuration for Aura-2
   - `api.toml` - Configuration for the Aura-2 API service
   - `license.toml` - License file for the Aura-2 Engine service

   Place these files in the `config` directory you created in step 1.

## Customize Your Configuration

Once you have downloaded all provided files to your deployment machine, you need to update your configuration for your specific deployment environment.

### Credentials

You will need to have an environment variable `DEEPGRAM_API_KEY` exported with your self-hosted API key secret. See our [Self Service Licensing & Credentials](/docs/on-prem-self-service-tutorial#create-an-on-prem-api-key) guide for instructions on generating a self-hosted API key for use in this section.

<Warning>
  Per the link above, you will create you self-hosted API key in the `API Key` tab of Deepgram Console. These are *not* created in the "Self-Hosted" tab, which is reserved for creating distribution credentials.
</Warning>

### Configuration Files

#### Compose File

The Docker Compose configuration file (`docker-config.yml`) provided by Deepgram makes it possible to spin up the containers using a single command. This file is specifically designed for the Aura-2 self-hosted deployment and uses the special container images:
- `quay.io/deepgram/self-hosted-aura-2-api:release-250501`
- `quay.io/deepgram/self-hosted-aura-2-engine:release-250501`

Make sure to export your self-hosted API key secret in your deployment environment.

<CodeGroup>
  ```bash shell
  export DEEPGRAM_API_KEY=API_KEY_SECRET
  ```
</CodeGroup>

#### `api.toml` and `license.toml`

The Aura-2 API container and Aura-2 Engine license are defined in these TOML files provided by Deepgram. These files contain settings specific to your Aura-2 deployment and need to be mounted to the containers (see the `volumes` section in the Compose file).

If you have any questions about modifying these files, reach out to your Deepgram Account Representative.

## Testing Your Containers

To make sure your Deepgram self-hosted deployment is properly configured and running, you will want to run the containers and make a sample request.

### Start the Deepgram Containers

Now that you have your configuration files setup up and in the correct location to be used by the container, use Docker Compose to run the container:

<CodeGroup>
  ```shell Shell
  cd config

  # Running without elevated privileges
  docker compose -f docker-config.yml up -d

  # Running with elevated privileges
  sudo --preserve-env=DEEPGRAM_API_KEY docker compose -f docker-config.yml up -d
  ```
</CodeGroup>

<Info>
  If you get an error similar to the following, you may not have the minimum NVIDIA driver version required for Deepgram services to run properly. Please see [Drivers and Containerization Platforms](/docs/drivers-and-containerization-platforms#download-and-install-the-official-drivers) for instructions on installing/upgrading to the latest driver version.
</Info>

You can then view the running containers with the container process status command, and optionally view the logs of each container to verify their status.

<CodeGroup>
  ```shell Shell
  docker ps
  # Take note of the "Container ID" for each Deepgram container
  docker logs CONTAINER_ID
  ```
</CodeGroup>

<Info>
  Replace the placeholder `CONTAINER_ID` with the Container ID of each container whose logs you would like to inspect more completely.
</Info>

### Networking Considerations

If you are running your API and Engine nodes on separate instances, you may need to add an inbound rule for port 8080 to the API instances' security group, so that port 8080 is reachable from where you are initiating your requests.

Unless you have HTTPS or TLS running on your API instance, construct your Deepgram API endpoint with `http://`, not `https://`, and `ws://`, not `wss://` (for instance, `http://localhost:8080/v1/listen`).

### Test Your Deepgram Setup with a Sample Request

Test your environment and container setup with a local file.

1. Send an Aura-2 speak request to your local Deepgram setup for voice synthesis.
   <CodeGroup>
     ```shell Shell
     # If needed, adjust the query parameters to match the directions from your Deepgram Account Representative
     curl --request POST \
        --header "Content-Type: application/json" \
        --output aura-2-output.wav \
        --data '{"text":"This is an Aura 2 self-hosted test."}' \
        --url "http://localhost:8080/v1/speak?model=aura-2-thalia-en"
     ```
   </CodeGroup>

<Info>
If you do not specify a `model`, the default voice model `aura-asteria-en` will be used. You can find all of our available voices [here](/docs/tts-models).
</Info>

You should receive an response with the audio output. You can copy this file locally to manually evaluate the synthesized speech within. Congratulations - your self-hosted Aura-2 setup is working!
