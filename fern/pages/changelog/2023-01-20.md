Deepgram released a new version of its on-premises solution.

### On-Premises Release 230120: Docker Hub Images

- `deepgram/onprem-api:1.78.0`
- `deepgram/onprem-engine:3.39.2`
  - Minimum required NVIDIA driver version: `>=450.80.02`


- `deepgram/onprem-license-proxy:1.2.5`
- `deepgram/onprem-billing:1.5.2`
- `deepgram/onprem-metrics-server:2.0.2`

### Changes

- Improvements to capitalization and punctuation output with the request parameter `punctuate=true`.
- Improved NLU usage reporting.
- The `/status` endpoint now returns an `HTTP 204` code instead of `HTTP 200`.
- Several improvements to streaming:
  - Now returns `model_info` in streaming responses.
  - Resolves an issue which causes streaming usage to be incorrectly reported.
  - Resolves an issue when making a streaming request which might cause the incorrect model `tier` to be used.
  - Resolves an issue with streaming web socket callbacks which might cause the connection to be prematurely terminated.


- Resolves an issue with support for audio data that uses the the [A-law algorithm](https://en.wikipedia.org/wiki/A-law_algorithm).
- Resolves several CVEs for the following images:
  - `deepgram/onprem-api`
  - `deepgram/onprem-license-proxy`
  - `deepgram/onprem-billing`
  - `deepgram/onprem-metrics-server`


- Other minor stability and performance improvements.

