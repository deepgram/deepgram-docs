---
title: Getting Started
subtitle: >-
  An introduction to using Deepgram's Voice Agent API to build interactive voice
  agents.
slug: docs/voice-agent
---


<Markdown src="../snippets/voice-agent.mdx" />

In this guide, you'll learn how to develop applications using Deepgram's Agent API. Visit the [API Reference](/reference/build-a-voice-agent) for more details on how to use the Agent API.

<Info>
  Before you start, you'll need to follow the steps in the [Make Your First API Request](/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.
</Info>

## API Playground

First, explore the Voice Agent in our API Playground where you can quickly interact with the Agent API using Deepgram's API Playground.

<div class="api-playground-call">
<span>
<img src="https://res.cloudinary.com/deepgram/image/upload/v1717523786/devex/codey-greeting_rekqe1.svg" alt="Deepgram API Playground"/>  Try this feature out in our [API Playground](https://playground.deepgram.com/?endpoint=agent)!
</span>
</div>

## Build a Basic Voice Agent

Deepgram has several SDKs that can make it easier to use the API. Follow these steps to use the SDK of your choice to make a Deepgram Voice Agent request.

### 1. Install the SDK

Open your terminal, navigate to the location on your drive where you want to create your project, and install the Deepgram SDK.

<CodeGroup>
  ```shell Python
  pip install deepgram-sdk
  ```

  ```shell JavaScript
  npm install @deepgram/sdk
  - or -
  yarn add @deepgram/sdk
  ```

  ```shell C#
  dotnet add package Deepgram
  ```

  ```shell Go
  go get github.com/deepgram/deepgram-go-sdk
  ```
</CodeGroup>

### 2. Initialize the WebSocket Connection

Create a WebSocket connection to the Deepgram Voice Agent API endpoint. The connection requires authentication using your API key.

@TODO: Check this code for accuracy

<CodeGroup>
  ```python Python
  import websockets

  async def connect_to_agent():
      ws = await websockets.connect(
          "wss://agent.deepgram.com/agent",
          subprotocols=["token", "YOUR_DEEPGRAM_API_KEY"]
      )
      return ws
  ```

  ```javascript JavaScript
  const ws = new WebSocket('wss://agent.deepgram.com/agent', ['token', 'YOUR_DEEPGRAM_API_KEY']);
  ```

  ```csharp C#
  var client = new DeepgramClient("YOUR_DEEPGRAM_API_KEY");
  var ws = await client.Agent.ConnectAsync();
  ```

  ```go Go
  import (
    "github.com/deepgram/deepgram-go-sdk"
  )
  client := deepgram.NewClient("YOUR_DEEPGRAM_API_KEY")
  ws, err := client.Agent.Connect()
  ```
</CodeGroup>

### 3. Configure the Agent

@TODO: Check this code for accuracy

Send a Settings message to configure the agent's behavior and audio formats. This must be done immediately after establishing the connection.

<CodeGroup>
  ```json JSON
  {
    "type": "Settings",
    "audio": {
      "input": {
        "encoding": "linear16",
        "sample_rate": 24000
      },
      "output": {
        "encoding": "linear16",
        "sample_rate": 24000
      }
    },
    "agent": {
      "language": "en",
      "listen": {
        "provider": {
          "type": "deepgram",
          "model": "nova-3"
        }
      },
      "think": {
        "provider": {
          "type": "open_ai",
          "model": "gpt-4",
          "temperature": 0.7
        }
      },
      "speak": {
        "provider": {
          "type": "deepgram",
          "model": "aura-2-thalia-en"
        }
      }
    }
  }
  ```
</CodeGroup>

<Info>
  You'll receive a [SettingsApplied](/docs/voice-agent-settings-applied-message) message when the configuration is successful.
</Info>

### 4. Handle Audio Streams

@TODO: Check this code for accuracy

Set up handlers for sending and receiving audio data. The agent expects raw audio data in the configured format.

<CodeGroup>
  ```python Python
  async def handle_audio(ws):
      # Send audio data
      await ws.send(audio_data)  # Binary audio data

      # Receive audio responses
      async for message in ws:
          if isinstance(message, bytes):
              # Handle binary audio data
              play_audio(message)
          elif isinstance(message, str):
              # Handle JSON messages
              handle_json_message(json.loads(message))
  ```
  ```javascript JavaScript
  ws.onmessage = function(event) {
    const message = JSON.parse(event.data);
    if (message.type === 'UserStartedSpeaking') {
      // Handle user speech detection
    }
  }
  ```
  ```csharp C#
  ws.OnMessage += (sender, eventArgs) => {
    var message = JsonConvert.DeserializeObject<JsonMessage>(eventArgs.Message);
    if (message.Type == "UserStartedSpeaking") {
      // Handle user speech detection
    }
  }
  ```
  ```go Go
  ws.OnMessage = func(message []byte) {
    var jsonMessage JsonMessage
    err := json.Unmarshal(message, &jsonMessage)
    if err != nil {
```
</CodeGroup>

@TODO: Check this code for accuracy

### 5. Process Agent Responses

Handle different types of server messages to manage the conversation flow.

<CodeGroup>
  ```python Python
  def handle_json_message(message):
      if message["type"] == "UserStartedSpeaking":
          # Handle user speech detection
          pass
      elif message["type"] == "AgentThinking":
          # Handle agent processing
          pass
      elif message["type"] == "FunctionCallRequest":
          # Handle function calls
          pass
  ```

  ```javascript JavaScript
  ws.onmessage = function(event) {
    const message = JSON.parse(event.data);
    if (message.type === 'UserStartedSpeaking') {
      // Handle user speech detection
    }
  }
  ```
  ```csharp C#
  ws.OnMessage += (sender, eventArgs) => {
    var message = JsonConvert.DeserializeObject<JsonMessage>(eventArgs.Message);
    if (message.Type == "UserStartedSpeaking") {
      // Handle user speech detection
    }
  }
  ```
  ```go Go
  ws.OnMessage = func(message []byte) {
    var jsonMessage JsonMessage
    err := json.Unmarshal(message, &jsonMessage)
```
</CodeGroup>

### 6. Manage the Connection

@TODO: Check this code for accuracy

Keep the connection alive and handle proper closure.

<CodeGroup>
  ```python Python
  async def keep_alive(ws):
      while True:
          await ws.send(json.dumps({"type": "KeepAlive"}))
          await asyncio.sleep(8)  # Send every 8 seconds

  async def close_connection(ws):
      await ws.close()
  ```
  ```javascript JavaScript
  ws.onclose = function() {
    // Handle connection closure
  }
  ```
  ```csharp C#
  ws.OnClose += (sender, eventArgs) => {
    // Handle connection closure
  }
  ```
  ```go Go
  ws.OnClose = func() {
    // Handle connection closure
  }
  ```
</CodeGroup>

### 7. Store Responses

@TODO: Check this code for accuracy

For example purposes we'll store the conversational text and audio in a file.

<CodeGroup>
  ```python Python
  def store_response(audio_data, text_data):
      # Save audio to file
      with open("response.wav", "wb") as f:
          f.write(audio_data)

      # Save text to file
      with open("conversation.txt", "a") as f:
          f.write(text_data + "\n")
  ```
  ```javascript JavaScript
  ws.onmessage = function(event) {
    const message = JSON.parse(event.data);
    if (message.type === 'UserStartedSpeaking') {
      // Handle user speech detection
    }
  }
  ```
  ```csharp C#
  ws.OnMessage += (sender, eventArgs) => {
    var message = JsonConvert.DeserializeObject<JsonMessage>(eventArgs.Message);
    if (message.Type == "UserStartedSpeaking") {
      // Handle user speech detection
    }
  }
  ```
  ```go Go
  ws.OnMessage = func(message []byte) {
    var jsonMessage JsonMessage
    err := json.Unmarshal(message, &jsonMessage)
    if err != nil {
      // Handle error
    }
    if jsonMessage.Type == "UserStartedSpeaking" {
      // Handle user speech detection
    }
  }
  ```
</CodeGroup>

## Implementation Examples

To better understand how to build a more complex Voice Agent, check out the following examples for working code.

| Use Case                                                                    | Runtime / Language           | Repo                                                                                                                                          |
| --------------------------------------------------------------------------- | ---------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------- |
| Voice agent basic demo   | Node, TypeScript, JavaScript | [Deepgram Voice Agent Demo](https://github.com/deepgram-devs/deepgram-voice-agent-demo)                                                       |
| Voice agent medical assistant demo                                                    | Node, TypeScript, JavaScript        | [Deepgram Voice Agent Medical Assistant Demo](https://github.com/deepgram-devs/voice-agent-medical-assistant-demo)
| Voice agent demo with Twilio                              | Python                       | [Python Twilio > Voice Agent Demo](/docs/twilio-and-deepgram-voice-agent)                                                                     |
| Voice agent demo with text input    | Node, TypeScript, JavaScript | [Deepgram Conversational AI Demo](https://github.com/deepgram-devs/deepgram-ai-agent-demo)                                                    |
| Voice agent with Azure Open AI Services | Python                       | [Deepgram Voice Agent with OpenAI Azure](https://github.com/deepgram-devs/voice-agent-azure-open-ai-services)                                 |
| Voice agent with Function Calling using Python Flask          | Python / Flask               | [Python Flask Agent Function Calling Demo](https://github.com/deepgram-devs/flask-agent-function-calling-demo)                                |
                                  |


## Rate Limits

<Info>
  For information on Deepgram's Concurrency Rate Limits, refer to our [API Rate Limits Documentation](/reference/api-rate-limits).
</Info>

## Usage Tracking

Usage is calculated based on websocket connection time. 1 hour of websocket connection time = 1 hour of API usage.

