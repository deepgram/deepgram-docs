---
title: Getting Started
subtitle: >-
  An introduction to using Deepgram's Voice Agent API to build interactive voice
  agents.
slug: docs/voice-agent
---


<Markdown src="../snippets/voice-agent.mdx" />

In this guide, you'll learn how to create a very basic voice agent using Deepgram's Agent API. Visit the [API Reference](/reference/build-a-voice-agent) for more details on how to use the Agent API.

<Info>
  Before you start, you'll need to follow the steps in the [Make Your First API Request](/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.
</Info>

## API Playground

Explore the Voice Agent API in our API Playground where you can quickly interact with the Agent API.

<div class="api-playground-call">
<span>
<img src="https://res.cloudinary.com/deepgram/image/upload/v1717523786/devex/codey-greeting_rekqe1.svg" alt="Deepgram API Playground"/>  Try this feature out in our [API Playground](https://playground.deepgram.com/?endpoint=agent)!
</span>
</div>

## Build a Basic Voice Agent

### 1. Set up your environment

In the steps below, you'll use the Terminal to:

1. Create a new directory for your project
2. Create a new file for your code
3. Export your Deepgram API key to the environment so you can use it in your code
4. Run any additional commands to initialize your project

<CodeGroup>
  ```shell Python
mkdir deepgram-agent-demo
cd deepgram-agent-demo
touch index.py
export DEEPGRAM_API_KEY="your_Deepgram_API_key_here"
@TODO other Python commands
  ```

  ```shell JavaScript
mkdir deepgram-agent-demo
cd deepgram-agent-demo
touch index.js
export DEEPGRAM_API_KEY="your_Deepgram_API_key_here"
npm init -y
  ```

  ```shell C#
# for MacOS
mkdir deepgram-agent-demo
cd deepgram-agent-demo
dotnet new console
export DEEPGRAM_API_KEY="your_Deepgram_API_key_here"

# for Windows Powershell
mkdir deepgram-agent-demo
cd deepgram-agent-demo
dotnet new console
$env:DEEPGRAM_API_KEY = "your_Deepgram_API_key_here"
  ```

  ```shell Go
mkdir deepgram-agent-demo
cd deepgram-agent-demo
touch index.go
go other Go commands
  ```
</CodeGroup>

### 2. Install the Deepgram SDK

Deepgram has several [SDKs](/docs/deepgram-sdks) that can make it easier to build a Voice Agent. Follow these steps below to use one of our SDKs to make your first Deepgram Voice Agent request.

In your terminal, navigate to the location on your drive where you created your project above, and install the Deepgram SDK and any other dependencies.

<CodeGroup>
  ```shell Python
  pip install deepgram-sdk
  ```

  ```shell JavaScript
  npm install @deepgram/sdk cross-fetch
  - or -
  yarn add @deepgram/sdk cross-fetch
  ```

  ```shell C#
  dotnet add package Deepgram
  ```

  ```shell Go
  go get github.com/deepgram/deepgram-go-sdk
  ```
</CodeGroup>

### 3. Import dependencies and set up the main function

Next, import the necessary dependencies and set up your main application function.

<CodeGroup>
  ```python Python
  @TODO
  ```

  ```javascript JavaScript
  const { createClient, AgentEvents } = require("@deepgram/sdk");
  const { writeFile, appendFile } = require("fs/promises");
  const fetch = require("cross-fetch");
  const { join } = require("path");

  const agent = async () => {
      // The code in the following steps will go here
  };

  void agent();
  ```
  ```csharp C#
@TODO
  ```

  ```go Go
  @TODO
  ```
</CodeGroup>

### 4. Initialize the Voice Agent

Now you can initialize the voice agent by creating an empty audio buffer to store incoming audio data, setting up a counter for output file naming, and defining a sample audio file URL. You can then establish a connection to Deepgram and set up a welcome handler to log when the connection is successfully established.

<Info>
This example code doesn't use microphone audio input as that is much more complex and requires additional knowledge of how to handle audio input through a microphone. Please refer to our [Voice Agent Starter Apps](/docs/voice-agent-starter-apps) for examples using microphone audio input.
</Info>

<CodeGroup>
  ```python Python
  @TODO
  ```
  ```javascript JavaScript
  let audioBuffer = Buffer.alloc(0);
  let i = 0;
  const url = "https://dpgr.am/spacewalk.wav";
  const connection = deepgram.agent();
  connection.on(AgentEvents.Welcome, () => {
    console.log("Welcome to the Deepgram Voice Agent!");
    // The code in the following steps will go here
  });

  ```
  ```csharp C#
  @TODO
  ```
  ```go Go
  @TODO
  ```
</CodeGroup>

### 5. Configure the Agent

Next you will need to set up a very simplified version of the [Settings](/docs/voice-agent-settings) message to configure your Agent's behavior and set the required settings options for your Agent.

<Info>
  To learn more about all settings options available for an Agent, refer to the [Configure the Voice Agent](/docs/configure-voice-agent) documentation.
</Info>

<CodeGroup>
  ```python Python
  @TODO
  ```

  ```javascript JavaScript
connection.configure({
      audio: {
        input: {
          encoding: "linear16",
          sample_rate: 24000,
        },
        output: {
          encoding: "linear16",
          sample_rate: 16000,
          container: "wav",
        },
      },
      agent: {
        language: "en",
        listen: {
          provider: {
            type: "deepgram",
            model: "nova-3",
          },
        },
        think: {
          provider: {
            type: "open_ai",
            model: "gpt-4o-mini",
          },
          prompt: "You are a friendly AI assistant.",
        },
        speak: {
          provider: {
            type: "deepgram",
            model: "aura-2-thalia-en",
          },
        },
        greeting: "Hello! How can I help you today?",
      },
    });

    console.log("Deepgram agent configured!");
  ```

  ```csharp C#
  @TODO
  ```

  ```go Go
  @TODO
  ```
</CodeGroup>

### 6. Send Keep Alive messages

Next you will send a keep-alive signal every 5 seconds to maintain the WebSocket connection. This prevents the connection from timing out during long audio processing. You will also fetch an audio file from the specified URL [spacewalk.wav](https://dpgr.am/spacewalk.wav) and stream the audio data in chunks to the Agent. Each chunk is sent as it becomes available in the readable stream.

<CodeGroup>
  ```python Python
  @TODO

  ```
  ```javascript JavaScript

setInterval(() => {
      console.log("Keep alive!");
      connection.keepAlive();
    }, 5000);

    fetch(url)
      .then((r) => r.body)
      .then((res) => {
        res.on("readable", () => {
          console.log("Sending audio chunk");
          connection.send(res.read());
        });
      });
  ```
  ```csharp C#
  @TODO
  ```
  ```go Go
  @TODO
```
</CodeGroup>

### 6. Setup Event Handlers

Next you will use this code to set up event handlers for the voice agent to manage the entire conversation lifecycle, from connection opening to closing. It handles audio processing by collecting chunks into a buffer and saving completed responses as WAV files, while also managing interruptions, logging conversations, and handling errors.

<CodeGroup>
  ```python Python
 @TODO
  ```
  ```javascript JavaScript

  connection.on(AgentEvents.Open, () => {
    console.log("Connection opened");
  });

  connection.on(AgentEvents.Close, () => {
    console.log("Connection closed");
    process.exit(0);
  });

  connection.on(AgentEvents.ConversationText, async (data) => {
    await appendFile(join(__dirname, `chatlog.txt`), JSON.stringify(data) + "\n");
  });

  connection.on(AgentEvents.UserStartedSpeaking, () => {
    if (audioBuffer.length) {
      console.log("Interrupting agent.");
      audioBuffer = Buffer.alloc(0);
    }
  });

  connection.on(AgentEvents.Metadata, (data) => {
    console.dir(data, { depth: null });
  });

  connection.on(AgentEvents.Audio, (data) => {
    console.log("Audio chunk received");
    // Concatenate the audio chunks into a single buffer
    const buffer = Buffer.from(data);
    audioBuffer = Buffer.concat([audioBuffer, buffer]);
  });

  connection.on(AgentEvents.Error, (err) => {
    console.error("Error!");
    console.error(JSON.stringify(err, null, 2));
    console.error(err.message);
  });

  connection.on(AgentEvents.AgentAudioDone, async () => {
    console.log("Agent audio done");
    await writeFile(join(__dirname, `output-${i}.wav`), audioBuffer);
    audioBuffer = Buffer.alloc(0);
    i++;
  });

  connection.on(AgentEvents.Unhandled, (data) => {
    console.dir(data, { depth: null });
  });
};

  ```
  ```csharp C#
  @TODO
  ```
  ```go Go
  @TODO
  ```
</CodeGroup>

### 7. Run the Voice Agent
Now that you have your complete code, you can run the Voice Agent! If it works you should see the conversation text and audio in the files: `output-0.wav` and `chatlog.txt`. These files will be saved in the same directory as your main application file.

<CodeGroup>
  ```python Python
  @TODO
  ```
  ```javascript JavaScript
  node index.js
  ```
  ```csharp C#
  dotnet run Program.cs
  ```
  ```go Go
  @TODO
  ```
</CodeGroup>

### 8. Putting it all together

Below is the final code for the Voice Agent you just built. If you saw any errors after running your Agent, you can compare the code below to the code you wrote in the steps above to find and fix the errors.

<CodeGroup>
  ```python Python
  @TODO
  ```
  ```javascript JavaScript
const { writeFile, appendFile } = require("fs/promises");
const { createClient, AgentEvents } = require("@deepgram/sdk");
const fetch = require("cross-fetch");
const { join } = require("path");

const deepgram = createClient(process.env.DEEPGRAM_API_KEY);

const agent = async () => {
  let audioBuffer = Buffer.alloc(0);
  let i = 0;
  const url = "https://dpgr.am/spacewalk.wav";
  const connection = deepgram.agent();
  connection.on(AgentEvents.Welcome, () => {
    console.log("Welcome to the Deepgram Voice Agent!");

    connection.configure({
      audio: {
        input: {
          encoding: "linear16",
          sample_rate: 24000,
        },
        output: {
          encoding: "linear16",
          sample_rate: 16000,
          container: "wav",
        },
      },
      agent: {
        language: "en",
        listen: {
          provider: {
            type: "deepgram",
            model: "nova-3",
          },
        },
        think: {
          provider: {
            type: "open_ai",
            model: "gpt-4o-mini",
          },
          prompt: "You are a friendly AI assistant.",
        },
        speak: {
          provider: {
            type: "deepgram",
            model: "aura-2-thalia-en",
          },
        },
        greeting: "Hello! How can I help you today?",
      },
    });

    console.log("Deepgram agent configured!");

    setInterval(() => {
      console.log("Keep alive!");
      connection.keepAlive();
    }, 5000);

    fetch(url)
      .then((r) => r.body)
      .then((res) => {
        res.on("readable", () => {
          console.log("Sending audio chunk");
          connection.send(res.read());
        });
      });
  });

  connection.on(AgentEvents.Open, () => {
    console.log("Connection opened");
  });

  connection.on(AgentEvents.Close, () => {
    console.log("Connection closed");
    process.exit(0);
  });

  connection.on(AgentEvents.ConversationText, async (data) => {
    await appendFile(join(__dirname, `chatlog.txt`), JSON.stringify(data) + "\n");
  });

  connection.on(AgentEvents.UserStartedSpeaking, () => {
    if (audioBuffer.length) {
      console.log("Interrupting agent.");
      audioBuffer = Buffer.alloc(0);
    }
  });

  connection.on(AgentEvents.Metadata, (data) => {
    console.dir(data, { depth: null });
  });

  connection.on(AgentEvents.Audio, (data) => {
    console.log("Audio chunk received");
    // Concatenate the audio chunks into a single buffer
    const buffer = Buffer.from(data);
    audioBuffer = Buffer.concat([audioBuffer, buffer]);
  });

  connection.on(AgentEvents.Error, (err) => {
    console.error("Error!");
    console.error(JSON.stringify(err, null, 2));
    console.error(err.message);
  });

  connection.on(AgentEvents.AgentAudioDone, async () => {
    console.log("Agent audio done");
    await writeFile(join(__dirname, `output-${i}.wav`), audioBuffer);
    audioBuffer = Buffer.alloc(0);
    i++;
  });

  connection.on(AgentEvents.Unhandled, (data) => {
    console.dir(data, { depth: null });
  });
};

void agent();

  ```
  ```csharp C#
  @TODO
  ```
  ```go Go
  @TODO
  ```
</CodeGroup>

## Implementation Examples

To better understand how to build a more complex Voice Agent, check out the following examples for working code.

| Use Case                                                                    | Runtime / Language           | Repo                                                                                                                                          |
| --------------------------------------------------------------------------- | ---------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------- |
| Voice agent basic demo   | Node, TypeScript, JavaScript | [Deepgram Voice Agent Demo](https://github.com/deepgram-devs/deepgram-voice-agent-demo)                                                       |
| Voice agent medical assistant demo                                                    | Node, TypeScript, JavaScript        | [Deepgram Voice Agent Medical Assistant Demo](https://github.com/deepgram-devs/voice-agent-medical-assistant-demo)
| Voice agent demo with Twilio                              | Python                       | [Python Twilio > Voice Agent Demo](/docs/twilio-and-deepgram-voice-agent)                                                                     |
| Voice agent demo with text input    | Node, TypeScript, JavaScript | [Deepgram Conversational AI Demo](https://github.com/deepgram-devs/deepgram-ai-agent-demo)                                                    |
| Voice agent with Azure Open AI Services | Python                       | [Deepgram Voice Agent with OpenAI Azure](https://github.com/deepgram-devs/voice-agent-azure-open-ai-services)                                 |
| Voice agent with Function Calling using Python Flask          | Python / Flask               | [Python Flask Agent Function Calling Demo](https://github.com/deepgram-devs/flask-agent-function-calling-demo)                                |
                                  |


## Rate Limits

<Info>
  For information on Deepgram's Concurrency Rate Limits, refer to our [API Rate Limits Documentation](/reference/api-rate-limits).
</Info>

## Usage Tracking

Usage is calculated based on websocket connection time. 1 hour of websocket connection time = 1 hour of API usage.

