---
title: Getting Started
subtitle: >-
  An introduction to using Deepgram's Voice Agent API to build interactive voice
  agents.
slug: docs/voice-agent
---


<Markdown src="../snippets/voice-agent.mdx" />

In this guide, you'll learn how to create a very basic voice agent using Deepgram's Agent API. Visit the [API Reference](/reference/build-a-voice-agent) for more details on how to use the Agent API.

<Info>
  Before you start, you'll need to follow the steps in the [Make Your First API Request](/docs/make-your-first-api-request) guide to obtain a Deepgram API key, and configure your environment if you are choosing to use a Deepgram SDK.
</Info>

## API Playground

Explore the Voice Agent API in our API Playground where you can quickly interact with the Agent API.

<div class="api-playground-call">
<span>
<img src="https://res.cloudinary.com/deepgram/image/upload/v1717523786/devex/codey-greeting_rekqe1.svg" alt="Deepgram API Playground"/>  Try this feature out in our [API Playground](https://playground.deepgram.com/?endpoint=agent)!
</span>
</div>

## Build a Basic Voice Agent

### 1. Set up your environment

In the steps below, you'll use the Terminal to:

1. Create a new directory for your project
2. Create a new file for your code
3. Export your Deepgram API key to the environment so you can use it in your code
4. Run any additional commands to initialize your project

<CodeGroup>
  ```shell Python
mkdir deepgram-agent-demo
cd deepgram-agent-demo
touch index.py
export DEEPGRAM_API_KEY="your_Deepgram_API_key_here"
@TODO other Python commands
  ```

  ```shell JavaScript
mkdir deepgram-agent-demo
cd deepgram-agent-demo
touch index.js
export DEEPGRAM_API_KEY="your_Deepgram_API_key_here"
npm init -y
  ```

  ```shell C#
# for MacOS
mkdir deepgram-agent-demo
cd deepgram-agent-demo
dotnet new console
export DEEPGRAM_API_KEY="your_Deepgram_API_key_here"

# for Windows Powershell
mkdir deepgram-agent-demo
cd deepgram-agent-demo
dotnet new console
$env:DEEPGRAM_API_KEY = "your_Deepgram_API_key_here"
  ```

  ```shell Go
mkdir deepgram-agent-demo
cd deepgram-agent-demo
touch index.go
go other Go commands
  ```
</CodeGroup>

### 2. Install the Deepgram SDK

Deepgram has several [SDKs](/docs/deepgram-sdks) that can make it easier to build a Voice Agent. Follow these steps below to use one of our SDKs to make your first Deepgram Voice Agent request.

In your terminal, navigate to the location on your drive where you created your project above, and install the Deepgram SDK and any other dependencies.

<CodeGroup>
  ```shell Python
  pip install deepgram-sdk
  ```

  ```shell JavaScript
  npm install @deepgram/sdk cross-fetch
  - or -
  yarn add @deepgram/sdk cross-fetch
  ```

  ```shell C#
  dotnet add package Deepgram
  ```

  ```shell Go
  go get github.com/deepgram/deepgram-go-sdk
  ```
</CodeGroup>

### 3. Import dependencies and set up the main function

Next, import the necessary dependencies and set up your main application function.

<CodeGroup>
  ```python Python
  @TODO
  ```

  ```javascript JavaScript
  const { createClient, AgentEvents } = require("@deepgram/sdk");
  const { writeFile, appendFile } = require("fs/promises");
  const fetch = require("cross-fetch");
  const { join } = require("path");

  const agent = async () => {
      // The code in the following steps will go here
  };

  void agent();
  ```
  ```csharp C#
using Deepgram.Logger;
using Deepgram.Models.Authenticate.v1;
using Deepgram.Models.Agent.v2.WebSocket;
using System.Collections.Generic;
using System.Net.Http;

namespace SampleApp
{
    class Program
    {
        static async Task Main(string[] args)
        {
            try
            {
              // The code in the following steps will go here

  ```

  ```go Go
  @TODO
  ```
</CodeGroup>

### 4. Initialize the Voice Agent

Now you can initialize the voice agent by creating an empty audio buffer to store incoming audio data, setting up a counter for output file naming, and defining a sample audio file URL. You can then establish a connection to Deepgram and set up a welcome handler to log when the connection is successfully established.

<Info>
This example code doesn't use microphone audio input as that is much more complex and requires additional knowledge of how to handle audio input through a microphone. Please refer to our [Voice Agent Starter Apps](/docs/voice-agent-starter-apps) for examples using microphone audio input.
</Info>

<CodeGroup>
  ```python Python
  @TODO
  ```
  ```javascript JavaScript
  let audioBuffer = Buffer.alloc(0);
  let i = 0;
  const url = "https://dpgr.am/spacewalk.wav";
  const connection = deepgram.agent();
  connection.on(AgentEvents.Welcome, () => {
    console.log("Welcome to the Deepgram Voice Agent!");
    // The code in the following steps will go here
  });

  ```
  ```csharp C#
  // Initialize Library with default logging
                // Normal logging is "Info" level
                Deepgram.Library.Initialize(LogLevel.Debug);
                // OR very chatty logging
                //Deepgram.Library.Initialize(LogLevel.Verbose); // LogLevel.Default, LogLevel.Debug, LogLevel.Verbose

                Console.WriteLine("\n\nPress any key to stop and exit...\n\n\n");

                // Set "DEEPGRAM_API_KEY" environment variable to your Deepgram API Key
                DeepgramWsClientOptions options = new DeepgramWsClientOptions(null, null, true);
                var agentClient = ClientFactory.CreateAgentWebSocketClient(apiKey: "", options: options);

                // current time
                var lastAudioTime = DateTime.Now;
                var audioFileCount = 0;
  ```
  ```go Go
  @TODO
  ```
</CodeGroup>

### 5. Configure the Agent

Next you will need to set up a very simplified version of the [Settings](/docs/voice-agent-settings) message to configure your Agent's behavior and set the required settings options for your Agent.

<Info>
  To learn more about all settings options available for an Agent, refer to the [Configure the Voice Agent](/docs/configure-voice-agent) documentation.
</Info>

<CodeGroup>
  ```python Python
  @TODO
  ```

  ```javascript JavaScript
connection.configure({
      audio: {
        input: {
          encoding: "linear16",
          sample_rate: 24000,
        },
        output: {
          encoding: "linear16",
          sample_rate: 16000,
          container: "wav",
        },
      },
      agent: {
        language: "en",
        listen: {
          provider: {
            type: "deepgram",
            model: "nova-3",
          },
        },
        think: {
          provider: {
            type: "open_ai",
            model: "gpt-4o-mini",
          },
          prompt: "You are a friendly AI assistant.",
        },
        speak: {
          provider: {
            type: "deepgram",
            model: "aura-2-thalia-en",
          },
        },
        greeting: "Hello! How can I help you today?",
      },
    });

    console.log("Deepgram agent configured!");
  ```

  ```csharp C#
       // Start the connection
                var settingsConfiguration = new SettingsSchema();
                settingsConfiguration.Agent.Think.Provider.Type = "open_ai";
                settingsConfiguration.Agent.Think.Provider.Model = "gpt-4o-mini";
                settingsConfiguration.Audio.Output.SampleRate = 16000;
                settingsConfiguration.Audio.Output.Container = "wav";
                settingsConfiguration.Audio.Input.SampleRate = 44100;
                settingsConfiguration.Agent.Greeting = "Hello, how can I help you today?";
                settingsConfiguration.Agent.Listen.Provider.Model = "nova-3";
                settingsConfiguration.Agent.Listen.Provider.Keyterms = new List<string> { "Deepgram" };
                settingsConfiguration.Agent.Speak.Provider.Type = "deepgram";
                settingsConfiguration.Agent.Speak.Provider.Model = "aura-2-thalia-en";

                // To avoid issues with empty objects, Voice and Endpoint are instantiated as null. Construct them as needed.
                // settingsConfiguration.Agent.Speak.Provider.Voice = new CartesiaVoice();
                // settingsConfiguration.Agent.Speak.Provider.Voice.Id = "en-US-Wavenet-D";
                // settingsConfiguration.Agent.Speak.Endpoint = new Endpoint();
                // settingsConfiguration.Agent.Think.Endpoint = new Endpoint();

                bool bConnected = await agentClient.Connect(settingsConfiguration);
                if (!bConnected)
                {
                    Console.WriteLine("Failed to connect to Deepgram WebSocket server.");
                    return;
                }
  ```

  ```go Go
  @TODO
  ```
</CodeGroup>

### 6. Send Keep Alive messages

Next you will send a keep-alive signal every 5 seconds to maintain the WebSocket connection. This prevents the connection from timing out during long audio processing. You will also fetch an audio file from the specified URL [spacewalk.wav](https://dpgr.am/spacewalk.wav) and stream the audio data in chunks to the Agent. Each chunk is sent as it becomes available in the readable stream.

<CodeGroup>
  ```python Python
  @TODO

  ```
  ```javascript JavaScript

setInterval(() => {
      console.log("Keep alive!");
      connection.keepAlive();
    }, 5000);

    fetch(url)
      .then((r) => r.body)
      .then((res) => {
        res.on("readable", () => {
          console.log("Sending audio chunk");
          connection.send(res.read());
        });
      });
  ```
  ```csharp C#
  N/A
  ```
  ```go Go
  @TODO
```
</CodeGroup>

### 6. Setup Event Handlers

Next you will use this code to set up event handlers for the voice agent to manage the entire conversation lifecycle, from connection opening to closing. It handles audio processing by collecting chunks into a buffer and saving completed responses as WAV files, while also managing interruptions, logging conversations, and handling errors.

<CodeGroup>
  ```python Python
 @TODO
  ```
  ```javascript JavaScript

  connection.on(AgentEvents.Open, () => {
    console.log("Connection opened");
  });

  connection.on(AgentEvents.Close, () => {
    console.log("Connection closed");
    process.exit(0);
  });

  connection.on(AgentEvents.ConversationText, async (data) => {
    await appendFile(join(__dirname, `chatlog.txt`), JSON.stringify(data) + "\n");
  });

  connection.on(AgentEvents.UserStartedSpeaking, () => {
    if (audioBuffer.length) {
      console.log("Interrupting agent.");
      audioBuffer = Buffer.alloc(0);
    }
  });

  connection.on(AgentEvents.Metadata, (data) => {
    console.dir(data, { depth: null });
  });

  connection.on(AgentEvents.Audio, (data) => {
    console.log("Audio chunk received");
    // Concatenate the audio chunks into a single buffer
    const buffer = Buffer.from(data);
    audioBuffer = Buffer.concat([audioBuffer, buffer]);
  });

  connection.on(AgentEvents.Error, (err) => {
    console.error("Error!");
    console.error(JSON.stringify(err, null, 2));
    console.error(err.message);
  });

  connection.on(AgentEvents.AgentAudioDone, async () => {
    console.log("Agent audio done");
    await writeFile(join(__dirname, `output-${i}.wav`), audioBuffer);
    audioBuffer = Buffer.alloc(0);
    i++;
  });

  connection.on(AgentEvents.Unhandled, (data) => {
    console.dir(data, { depth: null });
  });
};

  ```
  ```csharp C#
  // Subscribe to the EventResponseReceived event
                var subscribeResult = await agentClient.Subscribe(new EventHandler<OpenResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e.Type} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to OpenResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AudioResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e.Type} received");

                    // if the last audio response is more than 5 seconds ago, add a wav header
                    if (DateTime.Now.Subtract(lastAudioTime).TotalSeconds > 7)
                    {
                        audioFileCount = audioFileCount + 1; // increment the audio file count

                        // delete the file if it exists
                        if (File.Exists($"output_{audioFileCount}.wav"))
                        {
                            File.Delete($"output_{audioFileCount}.wav");
                        }

                        using (BinaryWriter writer = new BinaryWriter(File.Open($"output_{audioFileCount}.wav", FileMode.Append)))
                        {
                            Console.WriteLine("Adding WAV header to output.wav");
                            byte[] wavHeader = new byte[44];
                            int sampleRate = 48000;
                            short bitsPerSample = 16;
                            short channels = 1;
                            int byteRate = sampleRate * channels * (bitsPerSample / 8);
                            short blockAlign = (short)(channels * (bitsPerSample / 8));

                            wavHeader[0] = 0x52; // R
                            wavHeader[1] = 0x49; // I
                            wavHeader[2] = 0x46; // F
                            wavHeader[3] = 0x46; // F
                            wavHeader[4] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[5] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[6] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[7] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[8] = 0x57; // W
                            wavHeader[9] = 0x41; // A
                            wavHeader[10] = 0x56; // V
                            wavHeader[11] = 0x45; // E
                            wavHeader[12] = 0x66; // f
                            wavHeader[13] = 0x6D; // m
                            wavHeader[14] = 0x74; // t
                            wavHeader[15] = 0x20; // Space
                            wavHeader[16] = 0x10; // Subchunk1Size (16 for PCM)
                            wavHeader[17] = 0x00; // Subchunk1Size
                            wavHeader[18] = 0x00; // Subchunk1Size
                            wavHeader[19] = 0x00; // Subchunk1Size
                            wavHeader[20] = 0x01; // AudioFormat (1 for PCM)
                            wavHeader[21] = 0x00; // AudioFormat
                            wavHeader[22] = (byte)channels; // NumChannels
                            wavHeader[23] = 0x00; // NumChannels
                            wavHeader[24] = (byte)(sampleRate & 0xFF); // SampleRate
                            wavHeader[25] = (byte)((sampleRate >> 8) & 0xFF); // SampleRate
                            wavHeader[26] = (byte)((sampleRate >> 16) & 0xFF); // SampleRate
                            wavHeader[27] = (byte)((sampleRate >> 24) & 0xFF); // SampleRate
                            wavHeader[28] = (byte)(byteRate & 0xFF); // ByteRate
                            wavHeader[29] = (byte)((byteRate >> 8) & 0xFF); // ByteRate
                            wavHeader[30] = (byte)((byteRate >> 16) & 0xFF); // ByteRate
                            wavHeader[31] = (byte)((byteRate >> 24) & 0xFF); // ByteRate
                            wavHeader[32] = (byte)blockAlign; // BlockAlign
                            wavHeader[33] = 0x00; // BlockAlign
                            wavHeader[34] = (byte)bitsPerSample; // BitsPerSample
                            wavHeader[35] = 0x00; // BitsPerSample
                            wavHeader[36] = 0x64; // d
                            wavHeader[37] = 0x61; // t
                            wavHeader[38] = 0x74; // t
                            wavHeader[39] = 0x61; // a
                            wavHeader[40] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[41] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[42] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[43] = 0x00; // Placeholder for data chunk size (will be updated later)

                            writer.Write(wavHeader);
                        }
                    }

                    if (e.Stream != null)
                    {
                        using (BinaryWriter writer = new BinaryWriter(File.Open($"output_{audioFileCount}.wav", FileMode.Append)))
                        {
                            writer.Write(e.Stream.ToArray());
                        }
                    }

                    // record the last audio time
                    lastAudioTime = DateTime.Now;
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AudioResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentAudioDoneResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentAudioDoneResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentStartedSpeakingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentStartedSpeakingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentThinkingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentThinkingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<ConversationTextResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to ConversationTextResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<UserStartedSpeakingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to UserStartedSpeakingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<WelcomeResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to WelcomeResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<CloseResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to CloseResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<SettingsAppliedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to SettingsAppliedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<InjectionRefusedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to InjectionRefusedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<PromptUpdatedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to PromptUpdatedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<SpeakUpdatedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received.");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to SpeakUpdatedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<UnhandledResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to UnhandledResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<ErrorResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received. Error: {e.Message}");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to ErrorResponse event");
                    return;
                }

                // Fetch and stream audio from URL
                string url = "https://dpgr.am/spacewalk.wav";
                using (var httpClient = new HttpClient())
                {
                    var response = await httpClient.GetAsync(url);
                    var stream = await response.Content.ReadAsStreamAsync();
                    var buffer = new byte[8192];
                    int bytesRead;

                    while ((bytesRead = await stream.ReadAsync(buffer, 0, buffer.Length)) > 0)
                    {
                        var chunk = new byte[bytesRead];
                        Array.Copy(buffer, chunk, bytesRead);
                        await agentClient.SendBinaryImmediately(chunk);
                    }
                }

                // Wait for the user to press a key
                Console.ReadKey();

                // Stop the connection
                await agentClient.Stop();

                // Terminate Libraries
                Deepgram.Library.Terminate();
            }
            catch (Exception ex)
            {
                Console.WriteLine($"Exception: {ex.Message}");
            }
        }
    }
}
  ```
  ```go Go
  @TODO
  ```
</CodeGroup>

### 7. Run the Voice Agent
Now that you have your complete code, you can run the Voice Agent! If it works you should see the conversation text and audio in the files: `output-0.wav` and `chatlog.txt`. These files will be saved in the same directory as your main application file.

<CodeGroup>
  ```python Python
  @TODO
  ```
  ```javascript JavaScript
  node index.js
  ```
  ```csharp C#
  dotnet run Program.cs
  ```
  ```go Go
  @TODO
  ```
</CodeGroup>

### 8. Putting it all together

Below is the final code for the Voice Agent you just built. If you saw any errors after running your Agent, you can compare the code below to the code you wrote in the steps above to find and fix the errors.

<CodeGroup>
  ```python Python
  @TODO
  ```
  ```javascript JavaScript
const { writeFile, appendFile } = require("fs/promises");
const { createClient, AgentEvents } = require("@deepgram/sdk");
const fetch = require("cross-fetch");
const { join } = require("path");

const deepgram = createClient(process.env.DEEPGRAM_API_KEY);

const agent = async () => {
  let audioBuffer = Buffer.alloc(0);
  let i = 0;
  const url = "https://dpgr.am/spacewalk.wav";
  const connection = deepgram.agent();
  connection.on(AgentEvents.Welcome, () => {
    console.log("Welcome to the Deepgram Voice Agent!");

    connection.configure({
      audio: {
        input: {
          encoding: "linear16",
          sample_rate: 24000,
        },
        output: {
          encoding: "linear16",
          sample_rate: 16000,
          container: "wav",
        },
      },
      agent: {
        language: "en",
        listen: {
          provider: {
            type: "deepgram",
            model: "nova-3",
          },
        },
        think: {
          provider: {
            type: "open_ai",
            model: "gpt-4o-mini",
          },
          prompt: "You are a friendly AI assistant.",
        },
        speak: {
          provider: {
            type: "deepgram",
            model: "aura-2-thalia-en",
          },
        },
        greeting: "Hello! How can I help you today?",
      },
    });

    console.log("Deepgram agent configured!");

    setInterval(() => {
      console.log("Keep alive!");
      connection.keepAlive();
    }, 5000);

    fetch(url)
      .then((r) => r.body)
      .then((res) => {
        res.on("readable", () => {
          console.log("Sending audio chunk");
          connection.send(res.read());
        });
      });
  });

  connection.on(AgentEvents.Open, () => {
    console.log("Connection opened");
  });

  connection.on(AgentEvents.Close, () => {
    console.log("Connection closed");
    process.exit(0);
  });

  connection.on(AgentEvents.ConversationText, async (data) => {
    await appendFile(join(__dirname, `chatlog.txt`), JSON.stringify(data) + "\n");
  });

  connection.on(AgentEvents.UserStartedSpeaking, () => {
    if (audioBuffer.length) {
      console.log("Interrupting agent.");
      audioBuffer = Buffer.alloc(0);
    }
  });

  connection.on(AgentEvents.Metadata, (data) => {
    console.dir(data, { depth: null });
  });

  connection.on(AgentEvents.Audio, (data) => {
    console.log("Audio chunk received");
    // Concatenate the audio chunks into a single buffer
    const buffer = Buffer.from(data);
    audioBuffer = Buffer.concat([audioBuffer, buffer]);
  });

  connection.on(AgentEvents.Error, (err) => {
    console.error("Error!");
    console.error(JSON.stringify(err, null, 2));
    console.error(err.message);
  });

  connection.on(AgentEvents.AgentAudioDone, async () => {
    console.log("Agent audio done");
    await writeFile(join(__dirname, `output-${i}.wav`), audioBuffer);
    audioBuffer = Buffer.alloc(0);
    i++;
  });

  connection.on(AgentEvents.Unhandled, (data) => {
    console.dir(data, { depth: null });
  });
};

void agent();

  ```
  ```csharp C#
  // Copyright 2024 Deepgram .NET SDK contributors. All Rights Reserved.
// Use of this source code is governed by a MIT license that can be found in the LICENSE file.
// SPDX-License-Identifier: MIT

using Deepgram.Logger;
using Deepgram.Models.Authenticate.v1;
using Deepgram.Models.Agent.v2.WebSocket;
using System.Collections.Generic;
using System.Net.Http;

namespace SampleApp
{
    class Program
    {
        static async Task Main(string[] args)
        {
            try
            {
                // Initialize Library with default logging
                // Normal logging is "Info" level
                Deepgram.Library.Initialize(LogLevel.Debug);
                // OR very chatty logging
                //Deepgram.Library.Initialize(LogLevel.Verbose); // LogLevel.Default, LogLevel.Debug, LogLevel.Verbose

                Console.WriteLine("\n\nPress any key to stop and exit...\n\n\n");

                // Set "DEEPGRAM_API_KEY" environment variable to your Deepgram API Key
                DeepgramWsClientOptions options = new DeepgramWsClientOptions(null, null, true);
                var agentClient = ClientFactory.CreateAgentWebSocketClient(apiKey: "", options: options);

                // current time
                var lastAudioTime = DateTime.Now;
                var audioFileCount = 0;

                // Start the connection
                var settingsConfiguration = new SettingsSchema();
                settingsConfiguration.Agent.Think.Provider.Type = "open_ai";
                settingsConfiguration.Agent.Think.Provider.Model = "gpt-4o-mini";
                settingsConfiguration.Audio.Output.SampleRate = 16000;
                settingsConfiguration.Audio.Output.Container = "wav";
                settingsConfiguration.Audio.Input.SampleRate = 44100;
                settingsConfiguration.Agent.Greeting = "Hello, how can I help you today?";
                settingsConfiguration.Agent.Listen.Provider.Model = "nova-3";
                settingsConfiguration.Agent.Listen.Provider.Keyterms = new List<string> { "Deepgram" };
                settingsConfiguration.Agent.Speak.Provider.Type = "deepgram";
                settingsConfiguration.Agent.Speak.Provider.Model = "aura-2-thalia-en";

                // To avoid issues with empty objects, Voice and Endpoint are instantiated as null. Construct them as needed.
                // settingsConfiguration.Agent.Speak.Provider.Voice = new CartesiaVoice();
                // settingsConfiguration.Agent.Speak.Provider.Voice.Id = "en-US-Wavenet-D";
                // settingsConfiguration.Agent.Speak.Endpoint = new Endpoint();
                // settingsConfiguration.Agent.Think.Endpoint = new Endpoint();

                bool bConnected = await agentClient.Connect(settingsConfiguration);
                if (!bConnected)
                {
                    Console.WriteLine("Failed to connect to Deepgram WebSocket server.");
                    return;
                }

                // Subscribe to the EventResponseReceived event
                var subscribeResult = await agentClient.Subscribe(new EventHandler<OpenResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e.Type} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to OpenResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AudioResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e.Type} received");

                    // if the last audio response is more than 5 seconds ago, add a wav header
                    if (DateTime.Now.Subtract(lastAudioTime).TotalSeconds > 7)
                    {
                        audioFileCount = audioFileCount + 1; // increment the audio file count

                        // delete the file if it exists
                        if (File.Exists($"output_{audioFileCount}.wav"))
                        {
                            File.Delete($"output_{audioFileCount}.wav");
                        }

                        using (BinaryWriter writer = new BinaryWriter(File.Open($"output_{audioFileCount}.wav", FileMode.Append)))
                        {
                            Console.WriteLine("Adding WAV header to output.wav");
                            byte[] wavHeader = new byte[44];
                            int sampleRate = 48000;
                            short bitsPerSample = 16;
                            short channels = 1;
                            int byteRate = sampleRate * channels * (bitsPerSample / 8);
                            short blockAlign = (short)(channels * (bitsPerSample / 8));

                            wavHeader[0] = 0x52; // R
                            wavHeader[1] = 0x49; // I
                            wavHeader[2] = 0x46; // F
                            wavHeader[3] = 0x46; // F
                            wavHeader[4] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[5] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[6] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[7] = 0x00; // Placeholder for file size (will be updated later)
                            wavHeader[8] = 0x57; // W
                            wavHeader[9] = 0x41; // A
                            wavHeader[10] = 0x56; // V
                            wavHeader[11] = 0x45; // E
                            wavHeader[12] = 0x66; // f
                            wavHeader[13] = 0x6D; // m
                            wavHeader[14] = 0x74; // t
                            wavHeader[15] = 0x20; // Space
                            wavHeader[16] = 0x10; // Subchunk1Size (16 for PCM)
                            wavHeader[17] = 0x00; // Subchunk1Size
                            wavHeader[18] = 0x00; // Subchunk1Size
                            wavHeader[19] = 0x00; // Subchunk1Size
                            wavHeader[20] = 0x01; // AudioFormat (1 for PCM)
                            wavHeader[21] = 0x00; // AudioFormat
                            wavHeader[22] = (byte)channels; // NumChannels
                            wavHeader[23] = 0x00; // NumChannels
                            wavHeader[24] = (byte)(sampleRate & 0xFF); // SampleRate
                            wavHeader[25] = (byte)((sampleRate >> 8) & 0xFF); // SampleRate
                            wavHeader[26] = (byte)((sampleRate >> 16) & 0xFF); // SampleRate
                            wavHeader[27] = (byte)((sampleRate >> 24) & 0xFF); // SampleRate
                            wavHeader[28] = (byte)(byteRate & 0xFF); // ByteRate
                            wavHeader[29] = (byte)((byteRate >> 8) & 0xFF); // ByteRate
                            wavHeader[30] = (byte)((byteRate >> 16) & 0xFF); // ByteRate
                            wavHeader[31] = (byte)((byteRate >> 24) & 0xFF); // ByteRate
                            wavHeader[32] = (byte)blockAlign; // BlockAlign
                            wavHeader[33] = 0x00; // BlockAlign
                            wavHeader[34] = (byte)bitsPerSample; // BitsPerSample
                            wavHeader[35] = 0x00; // BitsPerSample
                            wavHeader[36] = 0x64; // d
                            wavHeader[37] = 0x61; // t
                            wavHeader[38] = 0x74; // t
                            wavHeader[39] = 0x61; // a
                            wavHeader[40] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[41] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[42] = 0x00; // Placeholder for data chunk size (will be updated later)
                            wavHeader[43] = 0x00; // Placeholder for data chunk size (will be updated later)

                            writer.Write(wavHeader);
                        }
                    }

                    if (e.Stream != null)
                    {
                        using (BinaryWriter writer = new BinaryWriter(File.Open($"output_{audioFileCount}.wav", FileMode.Append)))
                        {
                            writer.Write(e.Stream.ToArray());
                        }
                    }

                    // record the last audio time
                    lastAudioTime = DateTime.Now;
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AudioResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentAudioDoneResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentAudioDoneResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentStartedSpeakingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentStartedSpeakingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<AgentThinkingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to AgentThinkingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<ConversationTextResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to ConversationTextResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<UserStartedSpeakingResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to UserStartedSpeakingResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<WelcomeResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to WelcomeResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<CloseResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to CloseResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<SettingsAppliedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to SettingsAppliedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<InjectionRefusedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to InjectionRefusedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<PromptUpdatedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to PromptUpdatedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<SpeakUpdatedResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received.");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to SpeakUpdatedResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<UnhandledResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to UnhandledResponse event");
                    return;
                }

                subscribeResult = await agentClient.Subscribe(new EventHandler<ErrorResponse>((sender, e) =>
                {
                    Console.WriteLine($"----> {e} received. Error: {e.Message}");
                }));
                if (!subscribeResult)
                {
                    Console.WriteLine("Failed to subscribe to ErrorResponse event");
                    return;
                }

                // Fetch and stream audio from URL
                string url = "https://dpgr.am/spacewalk.wav";
                using (var httpClient = new HttpClient())
                {
                    var response = await httpClient.GetAsync(url);
                    var stream = await response.Content.ReadAsStreamAsync();
                    var buffer = new byte[8192];
                    int bytesRead;

                    while ((bytesRead = await stream.ReadAsync(buffer, 0, buffer.Length)) > 0)
                    {
                        var chunk = new byte[bytesRead];
                        Array.Copy(buffer, chunk, bytesRead);
                        await agentClient.SendBinaryImmediately(chunk);
                    }
                }

                // Wait for the user to press a key
                Console.ReadKey();

                // Stop the connection
                await agentClient.Stop();

                // Terminate Libraries
                Deepgram.Library.Terminate();
            }
            catch (Exception ex)
            {
                Console.WriteLine($"Exception: {ex.Message}");
            }
        }
    }
}
  ```
  ```go Go
  @TODO
  ```
</CodeGroup>

## Implementation Examples

To better understand how to build a more complex Voice Agent, check out the following examples for working code.

| Use Case                                                                    | Runtime / Language           | Repo                                                                                                                                          |
| --------------------------------------------------------------------------- | ---------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------- |
| Voice agent basic demo   | Node, TypeScript, JavaScript | [Deepgram Voice Agent Demo](https://github.com/deepgram-devs/deepgram-voice-agent-demo)                                                       |
| Voice agent medical assistant demo                                                    | Node, TypeScript, JavaScript        | [Deepgram Voice Agent Medical Assistant Demo](https://github.com/deepgram-devs/voice-agent-medical-assistant-demo)
| Voice agent demo with Twilio                              | Python                       | [Python Twilio > Voice Agent Demo](/docs/twilio-and-deepgram-voice-agent)                                                                     |
| Voice agent demo with text input    | Node, TypeScript, JavaScript | [Deepgram Conversational AI Demo](https://github.com/deepgram-devs/deepgram-ai-agent-demo)                                                    |
| Voice agent with Azure Open AI Services | Python                       | [Deepgram Voice Agent with OpenAI Azure](https://github.com/deepgram-devs/voice-agent-azure-open-ai-services)                                 |
| Voice agent with Function Calling using Python Flask          | Python / Flask               | [Python Flask Agent Function Calling Demo](https://github.com/deepgram-devs/flask-agent-function-calling-demo)                                |
                                  |


## Rate Limits

<Info>
  For information on Deepgram's Concurrency Rate Limits, refer to our [API Rate Limits Documentation](/reference/api-rate-limits).
</Info>

## Usage Tracking

Usage is calculated based on websocket connection time. 1 hour of websocket connection time = 1 hour of API usage.

