---
title: Text to Speech Streaming
subtitle: >-
  An overview of the Deepgram JavaScript SDK and Deepgram text-to-speech
  streaming.
slug: docs/js-sdk-streaming-text-to-speech
---


The Deepgram JavaScript SDK now works in both server and browser environments. A proxy configuration is required for browser environments (see the section below).

## Installing the SDK

<CodeGroup>
  ```typescript TypeScript
  # Install the Deepgram JS SDK
  # https://github.com/deepgram/deepgram-js-sdk

  npm install @deepgram/sdk
  ```
</CodeGroup>

## Initializing the SDK

<CodeGroup>
  ```typescript TypeScript
  import { createClient } from "@deepgram/sdk";
  import fs from "fs";

  const deepgram = createClient("DEEPGRAM_API_KEY");
  ```
</CodeGroup>

## Make a Deepgram Text-to-Speech Request

Once the SDK is initialized, you can make a request to convert text into speech.

<CodeGroup>
  ```typescript TypeScript
  const fs = require("fs");
  const { createClient, LiveTTSEvents } = require("../../dist/main/index");

  const live = async () => {
    const text = "Hello, how can I help you today?";

    const deepgram = createClient(process.env.DEEPGRAM_API_KEY);

    const dgConnection = deepgram.speak.live({ model: "aura-asteria-en" });

    let audioBuffer = Buffer.alloc(0);

    dgConnection.on(LiveTTSEvents.Open, () => {
      console.log("Connection opened");

      // Send text data for TTS synthesis
      dgConnection.sendText(text);

      // Send Flush message to the server after sending the text
      dgConnection.flush();

      dgConnection.on(LiveTTSEvents.Close, () => {
        console.log("Connection closed");
      });

      dgConnection.on(LiveTTSEvents.Metadata, (data) => {
        console.dir(data, { depth: null });
      });

      dgConnection.on(LiveTTSEvents.Audio, (data) => {
        console.log("Deepgram audio data received");
        // Concatenate the audio chunks into a single buffer
        const buffer = Buffer.from(data);
        audioBuffer = Buffer.concat([audioBuffer, buffer]);
      });

      dgConnection.on(LiveTTSEvents.Flushed, () => {
        console.log("Deepgram Flushed");
        // Write the buffered audio data to a file when the flush event is received
        writeFile();
      });

      dgConnection.on(LiveTTSEvents.Error, (err) => {
        console.error(err);
      });
    });

    const writeFile = () => {
      if (audioBuffer.length > 0) {
        fs.writeFile("output.mp3", audioBuffer, (err) => {
          if (err) {
            console.error("Error writing audio file:", err);
          } else {
            console.log("Audio file saved as output.mp3");
          }
        });
        audioBuffer = Buffer.alloc(0); // Reset buffer after writing
      }
    };
  };

  live();
  ```
</CodeGroup>

## Audio Output Streaming

The audio bytes representing the converted text will stream or be passed to the client via the above `AudioData` event using the callback function.

It should be noted that these audio bytes are:

* Container-less audio. Meaning depending on the `encoding` value chosen, only the raw audio data is sent. As an example, if you choose `linear16` as your `encoding` for audio, a `WAV` header will not be sent. Please see these [Tips and Tricks](/docs/handling-audio-issues-in-text-to-speech) for more information.
* Not of standard size/length when received by the client. This is because the text is broken down into sounds representing the speech. Certain sounds chained together to form fragments of spoken words are different in length and content.

Depending on what the use case is for the generated audio bytes, please visit one of these guides to better help utilize these audio bytes for your use case:

* [Sending LLM Outputs to a WebSocket](/docs/send-llm-outputs-to-the-tts-web-socket)
* [Text Chunking for Streaming TTS Optimization](/docs/text-chunking-for-tts-streaming-optimization)
* [Handling Audio Issues in Text To Speech](/docs/handling-audio-issues-in-text-to-speech)

## Where to Find Additional Examples

The SDK repository has a good collection of text-to-speech examples. The [README](https://github.com/deepgram/deepgram-js-sdk/blob/main/README.md) contains links to them. Each example below attempts to provide different options for transcribing an audio source.

Some Example(s):

* Hello World - [examples/node-speak-live](https://github.com/deepgram/deepgram-js-sdk/blob/main/examples/node-speak-live/index.js)
