---
title: Text Chunking for TTS
subtitle: >-
  Basic techniques for breaking text into chunks to reduce latency in Text-to-Speech applications.
slug: docs/tts-text-chunking
---

## Why Text Chunking Matters

Text chunking significantly reduces perceived latency in TTS applications by allowing audio playback to begin sooner. This is especially important for conversational AI and voice agents where responsiveness is critical.

Instead of waiting for the entire audio to be generated, chunking lets you:
- Begin audio playback much faster
- Create more responsive voice experiences
- Maintain natural-sounding speech

## Basic Sentence Chunking

The simplest and most effective approach is to split text at sentence boundaries. This preserves natural speech patterns while enabling faster time-to-first-byte:

<CodeGroup>
```python
import re

def chunk_by_sentence(text):
    # Split text at sentence boundaries (periods, question marks, exclamation points)
    # while preserving the punctuation
    sentences = re.split(r'(?<=[.!?])\s+', text)
    
    # Remove any empty chunks
    return [sentence for sentence in sentences if sentence]

# Example usage
text = "Hello, welcome to Deepgram. This is an example of text chunking. How does it sound?"
chunks = chunk_by_sentence(text)

for i, chunk in enumerate(chunks):
    print(f"Chunk {i+1}: {chunk}")

# Output:
# Chunk 1: Hello, welcome to Deepgram.
# Chunk 2: This is an example of text chunking.
# Chunk 3: How does it sound?
```
```javascript Node.Js
function chunkBySentence(text) {
  // Split text at sentence boundaries (periods, question marks, exclamation points)
  // while preserving the punctuation
  const sentences = text.split(/(?<=[.!?])\s+/);

  // Remove any empty chunks
  return sentences.filter(sentence => sentence);
}

// Example usage
const text = "Hello, welcome to Deepgram. This is an example of text chunking. How does it sound?";
const chunks = chunkBySentence(text);

chunks.forEach((chunk, index) => {
  console.log(`Chunk ${index + 1}: ${chunk}`);
});

// Output:
// Chunk 1: Hello, welcome to Deepgram.
// Chunk 2: This is an example of text chunking.
// Chunk 3: How does it sound?
```
</CodeGroup>

## Processing Streaming Text with WebSockets

When working with streaming text (like from an LLM), you need to collect tokens until you have complete sentences. Here's a simplified approach to process text chunks that arrive as paragraphs:

<CodeGroup>
```python
import re
import asyncio
from deepgram import DeepgramClient, SpeakOptions

def chunk_by_sentence(text):
    # Split text at sentence boundaries (periods, question marks, exclamation points)
    # while preserving the punctuation
    sentences = re.split(r'(?<=[.!?])\s+', text)
    
    # Remove any empty chunks
    return [sentence for sentence in sentences if sentence]

class SimpleTextChunker:
    def __init__(self, tts_client):
        self.queue = []  # Queue to store incoming paragraph chunks
        self.processed_sentences = set()
        self.tts_client = tts_client

    async def process_text_stream(self, paragraph):
        """Process an array of paragraph chunks, each containing 1-2 sentences"""
        
        # Queue paragraph as it arrives (simulating fast reception)
        self.queue.append(paragraph)
        print(f"Received and queued paragraph: {paragraph}")

        # You could preprocess paragraphs here and split them by more than just sentence boundaries
        
        # Process the queue
        while self.queue:
            # Get the next paragraph from the queue
            paragraph = self.queue.pop(0)
            
            # Split paragraph into sentences using our chunk_by_sentence function
            sentences = chunk_by_sentence(paragraph)
            
            # Process each sentence
            for sentence in sentences:
                if sentence and sentence not in self.processed_sentences:
                    # Send the sentence to TTS
                    print(f"Sending sentence to TTS: {sentence}")
                    audio_response = await self.tts_client.sync_speak({
                        "text": sentence,
                        "model": "aura-2-thalia-en",
                        "sample_rate": 24000
                    })
                    # In a real app, you would play this audio immediately
                    self.processed_sentences.add(sentence)

# Example usage with an array of paragraph chunks
async def main():
    # This simulates text coming in as paragraph chunks from an LLM
    paragraph_chunks = [
        "Deepgram's TTS API offers low latency. It works great for voice agents.",
        "This approach simulates receiving chunks as paragraphs. Each paragraph may contain one or two sentences.",
        "Try it today! You'll be impressed with the results."
    ]

    # Set up TTS client
    deepgram = DeepgramClient()
    tts_client = deepgram.speak
    
    # Set up listeners for TTS events to handle audio data and connection status
    
    chunker = SimpleTextChunker(tts_client)
    # Process each paragraph sequentially
    for paragraph in paragraph_chunks:
        await chunker.process_text_stream(paragraph)

# Run the example
if __name__ == "__main__":
    asyncio.run(main())
```
```javascript Node.Js
// Text chunking utility for sentence-based splitting
function chunkBySentence(text) {
  // Split text at sentence boundaries while preserving punctuation
  const sentences = text.split(/(?<=[.!?])\s+/);
  
  // Remove any empty chunks
  return sentences.filter(sentence => sentence.trim().length > 0);
}

class SimpleTextChunker {
  constructor(ttsClient) {
    this.queue = [];  // Queue to store incoming paragraph chunks
    this.processedSentences = new Set();
    this.ttsClient = ttsClient;
  }
  
  async processTextStream(paragraph) {
    // Queue paragraph as it arrives
    this.queue.push(paragraph);
    console.log(`Received and queued paragraph: ${paragraph}`);
    
    // Process the queue
    while (this.queue.length > 0) {
      // Get the next paragraph from the queue
      const paragraph = this.queue.shift();
      
      // Split paragraph into sentences using our chunkBySentence function
      const sentences = chunkBySentence(paragraph);
      
      // Process each sentence sequentially
      for (const sentence of sentences) {
        if (sentence && !this.processedSentences.has(sentence)) {
          // Send the sentence to TTS
          console.log(`Sending sentence to TTS: ${sentence}`);
          
          try {
            // Using Deepgram Node SDK
            const audioResponse = await this.ttsClient.speak({
              text: sentence,
              model: "aura-2-thalia-en",
              sample_rate: 24000
            });
            
            // In a real app, you would play this audio immediately
            // For example with Web Audio API or saving to a file
            
            this.processedSentences.add(sentence);
          } catch (error) {
            console.error('Error generating speech:', error);
          }
        }
      }
    }
  }
}

// Example usage with an array of paragraph chunks
async function main() {
  const { DeepgramClient } = require('@deepgram/sdk');
  
  // This simulates text coming in as paragraph chunks from an LLM
  const paragraphChunks = [
    "Deepgram's TTS API offers low latency. It works great for voice agents.",
    "This approach simulates receiving chunks as paragraphs. Each paragraph may contain one or two sentences.",
    "Try it today! You'll be impressed with the results."
  ];
  
  // Set up TTS client
  const deepgram = new DeepgramClient({ apiKey: process.env.DEEPGRAM_API_KEY });
  const ttsClient = deepgram.speak;
  
  // In a real app, set up listeners for TTS events to handle audio data
  
  const chunker = new SimpleTextChunker(ttsClient);
  
  // Process each paragraph sequentially
  for (const paragraph of paragraphChunks) {
    await chunker.processTextStream(paragraph);
  }
}

// Run the example
main().catch(console.error);
```
</CodeGroup>

For complete details on implementing the TTS WebSocket connection, see our guide on [Real-Time TTS with WebSockets](/docs/tts-websocket-streaming).

## Processing Chunked Text

After creating chunks, you have two main options for processing them:

### Sequential Processing

Process each chunk in sequence, prioritizing the first chunk:

<CodeGroup>
```python
async def process_chunks_sequential(chunks, tts_function):
    results = []
    for i, chunk in enumerate(chunks):
        # You might prioritize the first chunk for faster response
        result = await tts_function(chunk)
        results.append(result)
    return results
```
```javascript Node.Js
async function processChunksSequential(chunks, ttsFunction) {
  const results = [];
  for (let i = 0; i < chunks.length; i++) {
    const chunk = chunks[i];
    // You might prioritize the first chunk for faster response
    const result = await ttsFunction(chunk);
    results.push(result);
  }
  return results;
}
```
</CodeGroup>

### Setting Chunk Size

For most applications, sentences work well as chunks. If you need finer control:

- **Voice assistants**: Aim for 50-100 character chunks
- **Call center bots**: Use complete sentences (most natural)
- **Long-form content**: Larger chunks (200-400 characters) preserve intonation

## Other Chunking Strategies

If you need more advanced chunking methods, search for these techniques:

- **Clause-based chunking**: Splits long sentences at commas and semicolons
- **NLP-based chunking**: Uses natural language processing to find semantic boundaries
- **Adaptive chunking**: Adjusts chunk size based on content complexity
- **First-chunk optimization**: Specially optimizes the first chunk for minimal latency
- **SSML chunking**: Handles Speech Synthesis Markup Language tags when chunking

<Info>
  For WebSocket implementation details to stream the chunked audio, see our guide on [Real-Time TTS with WebSockets](/docs/tts-websocket-streaming).
</Info>