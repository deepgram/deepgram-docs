---
title: LLM Models
subtitle: >-
  An overview of the LLM providers and models you can use with the Voice Agent
  API.
slug: docs/voice-agent-llm-models
---

Defines the LLM (*Large Language Model*) to be used with your Agent. The `provider.type` field specifies the format or protocol of the API.

For example:

- `open_ai` means the API follows OpenAI’s Chat Completions format.
- This option can be used with OpenAI, Azure OpenAI, or Amazon Bedrock — as long as the endpoint behaves like OpenAI’s Chat Completion API.


<Info>
  You can set your Voice Agent's LLM model in the [Settings Message](/docs/configure-voice-agent) See the docs for more information.
</Info>

## Supported LLM providers

<Info>
   If you don't specify `agent.think.provider.type` the Voice Agent will use Deepgram's LLM by default.
</Info>


| `agent.think.provider.type` | `agent.think.endpoint.url` | `agent.think.endpoint.headers` |
|-------------------|--------------------------|-----------------------------|
| `open_ai` | required | required |
| `anthropic` | required | required |
| `x_ai` | required | required |

## Example Payload

<CodeGroup>
  ```json JSON
  // ... other settings ...
   "think": {
        "provider": {
          "type": "open_ai",
          "model": "gpt-4",
          "temperature": 0.7
        },
        "endpoint": { // Optional if LLM provider is Deepgram. Required for non-Deepgram LLM providers
          "url": "https://api.example.com/llm",
          "headers": {
            "authorization": "Bearer {{token}}"
          }
        },
  // ... other settings ...
  ```
</CodeGroup>

## Passing a custom LLM through a Cloud Provider

You can use a custom LLM hosted by a 3rd party Cloud Provider by setting the `provider.type` to one of the supported provider values and setting the `endpoint.url` and `endpoint.headers` fields to the correct values for your Cloud Provider.

<CodeGroup>
  ```json JSON
  {
    // ... other settings ...
  "think": {
        "provider": {
          "type": "open_ai",
          "model": "gpt-4",
          "temperature": 0.7
        },
        "endpoint": { // Optional if LLM provider is Deepgram. Required for non-Deepgram LLM providers
          "url": "https://cloud.provider.com/llm",
          "headers": {
            "authorization": "Bearer {{token}}"
          }
        },
    // ... other settings ...
  }
  ```
</CodeGroup>
