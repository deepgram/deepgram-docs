---
title: Configure the Voice Agent
subtitle: >-
  Learn about the voice agent configuration options for the agent, and both
  input and output audio.
slug: docs/configure-voice-agent
---

<Warning>
You will need to migrate to the new ***Voice Agent API V1*** to continue to use the Voice Agent API. Please refer to the [Voice Agent API Migration Guide](/docs/voice-agent-v1-migration) for more information.
</Warning>

To configure your Voice Agent, you'll need to send a [Settings](/docs/voice-agent-settings) message immediately after connection. This message configures the agent's behavior, input/output audio formats, and various provider settings.

<Info>
For more information on the `Settings` message, see the [Voice Agent API Reference](/reference/voice-agent-api/agent)
</Info>

## Settings Overview

The `Settings` message is a JSON object that contains the following fields:

### Settings
| Parameter | Type | Description |
|-----------|------|-------------|
| `type` | String | Must be "Settings" to indicate this is a settings configuration message |
| `experimental` | Boolean | Enables experimental features. Defaults to `false` |

### Audio
| Parameter | Type | Description |
|-----------|------|-------------|
| `audio.input` | Object | The speech-to-text audio media input configuration |
| `audio.input.encoding` | String | The encoding format for the input audio. Defaults to `linear16` |
| `audio.input.sample_rate` | Integer | The sample rate in Hz for the input audio. Defaults to 16000 |
| `audio.output` | Object | The text-to-speech audio media output configuration |
| `audio.output.encoding` | String | The encoding format for the output audio |
| `audio.output.sample_rate` | Integer | The sample rate in Hz for the output audio |
| `audio.output.bitrate` | Integer | The bitrate in bits per second for the output audio |
| `audio.output.container` | String | The container format for the output audio. Defaults to `none` |

### Agent
| Parameter | Type | Description |
|-----------|------|-------------|
| `agent.language` | String | The language code for the agent. Defaults to `en` |
| `agent.listen.provider.type` | Object | The speech-to-text provider type. Currently only Deepgram is supported |
| `agent.listen.provider.model` | String | The [Deepgram speech-to-text model](/docs/models-languages-overview) to be used |
| `agent.listen.provider.keyterms` | Array | The [Keyterms](/docs/keyterms) you want increased recognition for |
| `agent.think.provider.type` | Object | The [LLM Model](/docs/voice-agent-llm-models) provider type e.g., `open_ai`, `anthropic`, `x_ai`, `amazon_bedrock` |
| `agent.think.provider.model` | String | The LLM model to use|
| `agent.think.provider.temperature` | Number | Controls the randomness of the LLM's output. Range: 0-2 for OpenAI, 0-1 for Anthropic |
| `agent.think.endpoint` | Object | Optional if LLM provider is Deepgram. Required for non-Deepgram LLM providers. When present, must include `url` field and `headers` object |
| `agent.think.functions` | Array | Array of functions the agent can call during the conversation |
| `agent.think.functions.endpoint` | Object | The Function endpoint to call. if not passed, function is called client-side |
| `agent.think.prompt` | String | The system prompt that defines the agent's behavior and personality |
| `agent.think.context_length` | Integer or String | Specifies the number of characters retained in context between user messages, agent responses, and function calls. This setting is only configurable when a custom think endpoint is used. Use `max` for maximum context length. |
| `agent.speak.provider.type` | Object | The [TTS Model](/docs/voice-agent-tts-models) provider type. e.g., `deepgram`, `eleven_labs`, `cartesia`, `open_ai` |
| `agent.speak.provider.model` | String | The [TTS Model](/docs/voice-agent-tts-models)  to use for Deepgram or OpenAI |
| `agent.speak.provider.model_id` | String| The [TTS Model](/docs/voice-agent-tts-models) ID to use for Eleven Labs or Cartesia |
| `agent.speak.provider.voice` | Object | Voice configuration for Cartesia provider. Requires `model` and `id` |
| `agent.speak.provider.language` | String | Optional language setting for Cartesia provider |
| `agent.speak.provider.language_code` | String | Optional language code for Eleven Labs provider |
| `agent.speak.provider.engine` | String | Optional engine for AWS Polly provider |
| `agent.speak.provider.credentials` | Object | Optional credentials for AWS Polly provider. When present, must include  `type`,`region`, `access_key_id`, `secret_access_key` and `session_token` if STS is used |
| `agent.speak.endpoint` | Object | Optional if TTS provider is Deepgram. Required for non-Deepgram TTS providers. When present, must include `url` field and `headers` object |
| `agent.greeting` | String | Optional initial message that the agent will speak when the conversation starts |

#### `agent.language`

* Choose your language setting based on your use case:
  - If you know your input language, specify it directly for the best recognition accuracy.
  - If you expect multiple languages or are unsure, use `multi` for flexible language support.
  - Currently `multi` is only supported with [Eleven Labs TTS](/docs/voice-agent-tts-models#eleven-labs)
  - Refer to our [supported languages](/docs/models-languages-overview) to ensure you're using the correct model (Nova-2 or Nova-3) for your selected language.

#### `agent.think.context_length`

* Using `max` will set the context length to the maximum allowed based on the LLM provider you use. If the total context exceeds the model's maximum, truncation is handled by the LLM provider.
* Increasing the context length may help preserve multi-turn conversation history, especially when verbose function calls inflate the total context.
* All characters sent to the LLM count toward the context limit, including fully serialized JSON messages, function call arguments, and responses. System messages are excluded and managed separately via `agent.think.prompt`.
* The default context length set by Deepgram is optimized for cost and latency. It is not recommended to change this setting unless there's a clear need.


## Full Example

Below is an in-depth example showing all the available fields for `Settings` with all the optional fields for individual provider specific settings.

<CodeGroup>
  ```json JSON
  {
    "type": "Settings",
    "experimental": false,
    "mip_opt_out": false,
    "audio": {
      "input": {
        "encoding": "linear16",
        "sample_rate": 24000
      },
      "output": {
        "encoding": "mp3",
        "sample_rate": 24000,
        "bitrate": 48000,
        "container": "none"
      }
    },
    "agent": {
      "language": "en",
      "listen": {
        "provider": {
          "type": "deepgram",
          "model": "nova-3",
          "keyterms": ["hello", "goodbye"]
        }
      },
      "think": {
        "provider": {
          "type": "open_ai",
          "model": "gpt-4o-mini",
          "temperature": 0.7
        },
        "endpoint": { // Optional for non-Deepgram LLM providers. When present, must include url field and headers object
          "url": "https://api.example.com/llm",
          "headers": {
            "authorization": "Bearer {{token}}"
          }
        },
        "prompt": "You are a helpful AI assistant focused on customer service.",
        "context_length": 15000,  // Optional and can only be used when a custom think endpoint is used. Use max for maximum context length
        "functions": [
          {
            "name": "check_order_status",
            "description": "Check the status of a customer order",
            "parameters": {
              "type": "object",
              "properties": {
                "order_id": {
                  "type": "string",
                  "description": "The order ID to check"
                }
              },
              "required": ["order_id"]
            },
            "endpoint": { // If not provided, function is called client-side
              "url": "https://api.example.com/orders/status",
              "method": "post",
              "headers": {
                "authorization": "Bearer {{token}}"
              }
            }
          }
        ]
      },
      "speak": {
        "provider": {
          "type": "deepgram",
          "model": "aura-2-thalia-en", // Optional if TTS provider is Deepgram. Use for OpenAI OR Deepgram
          "model_id": "1234567890", // Optional if TTS provider is Deepgram. Use for Eleven Labs OR Cartesia
          "voice": {
            "mode": "Cartesia mode type", // Optional if TTS provider is Deepgram. Use for Cartesia
            "id": "voice id" // Optional if TTS provider is Deepgram. Use for Cartesia or OpenAI
          },
          "language": "en", // Optional if TTS provider is Deepgram. Use for Cartesia
          "language_code": "en-US", // Optional if TTS provider is Deepgram. Use for Eleven Labs
          "engine": "standard", // Optional if TTS provider is Deepgram. Use for AWS Polly
          "credentials": { // Optional if TTS provider is Deepgram. Use for AWS Polly
            "region": "us-east-1",
            "access_key_id": "{{access_key_id}}",
            "secret_access_key": "{{secret_access_key}}"
            "session_token": "{{session_token}}" // Optional if TTS provider is Deepgram. Use for AWS Polly STS
          }
        },
        "endpoint": {
          "url": "https://api.example.com/tts",
          "headers": {
            "authorization": "Bearer {{token}}"
          }
        }
      },
      "greeting": "Hello! How can I help you today?"
    }
  }
  ```
</CodeGroup>
